{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name Surname:\n",
        "\n",
        "Student No:\n",
        "\n",
        "---"
      ],
      "metadata": {
        "collapsed": false,
        "id": "bb36970405767267"
      },
      "id": "bb36970405767267"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libraries to be used\n",
        "\n",
        "---"
      ],
      "metadata": {
        "collapsed": false,
        "id": "492f60b5bb5b0611"
      },
      "id": "492f60b5bb5b0611"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "20147ee2b206ecf4"
      },
      "id": "20147ee2b206ecf4",
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logistic Regression (35 points)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "b37250ce98e63d7b"
      },
      "id": "b37250ce98e63d7b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression with MSE Loss (5 points)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "7985ce0ad919b23"
      },
      "id": "7985ce0ad919b23"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "class LogisticRegressionMSE:\n",
        "    def __init__(self, train_data, train_label, test_data, test_label, learning_rate=0.005, iterations=5000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations = iterations\n",
        "        self.train_data = train_data\n",
        "        self.train_label = train_label\n",
        "        self.test_data = test_data\n",
        "        self.test_label = test_label\n",
        "\n",
        "        n_samples, n_features = self.train_data.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Compute accuracy of train and test data every 100 iterations during training\n",
        "        self.accuracy_train_data_during_training = []\n",
        "        self.accuracy_test_data_during_training = []\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        # implement here\n",
        "        pass\n",
        "\n",
        "    def fit(self):\n",
        "        # implement here\n",
        "        pass\n",
        "\n",
        "    def predict(self, test_data):\n",
        "        # implement here\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression with Cross Entropy Loss (5 points)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1dd93577454d118"
      },
      "id": "1dd93577454d118"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "class LogisticRegressionCrossEntropy:\n",
        "    def __init__(self, train_data, train_label, test_data, test_label, learning_rate=0.005, iterations=5000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations = iterations\n",
        "        self.train_data = train_data\n",
        "        self.train_label = train_label\n",
        "        self.test_data = test_data\n",
        "        self.test_label = test_label\n",
        "\n",
        "        n_samples, n_features = self.train_data.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Compute accuracy of train and test data every 100 iterations during training\n",
        "        self.accuracy_train_data_during_training = []\n",
        "        self.accuracy_test_data_during_training = []\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        # implement here\n",
        "        pass\n",
        "\n",
        "    def fit(self):\n",
        "        # implement here\n",
        "        pass\n",
        "\n",
        "    def predict(self, test_data):\n",
        "        # implement here\n",
        "        pass"
      ],
      "metadata": {
        "id": "63c0d732bd96a004"
      },
      "id": "63c0d732bd96a004",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate your implementation using libraries (5 points)\n",
        "\n",
        "(you can generate synthetic data using numpy of import another toy dataset from sklearn)\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "c23db8b8eb8b4120"
      },
      "id": "c23db8b8eb8b4120"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "### fill here ###"
      ],
      "metadata": {
        "id": "d53c553c39dc5470"
      },
      "id": "d53c553c39dc5470",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment\n",
        "\n",
        "Dataset preparation"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6b918079bc6e0742"
      },
      "id": "6b918079bc6e0742"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "X = data[['Pclass', 'Sex', 'SibSp','Parch','Fare']].values\n",
        "Y = data['Survived'].values\n",
        "columns = data.columns\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "4b1f2be49d33a646"
      },
      "id": "4b1f2be49d33a646",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use two Logistic Regression Methods on the dataset directly (10 points)\n",
        "Show accuracy scores on test data"
      ],
      "metadata": {
        "collapsed": false,
        "id": "18be025b0b9ceeca"
      },
      "id": "18be025b0b9ceeca"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "### fill here ###"
      ],
      "metadata": {
        "id": "5a83809cfc29cb7e"
      },
      "id": "5a83809cfc29cb7e",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the training and test accuracy across the learning iterations of gradient descent"
      ],
      "metadata": {
        "collapsed": false,
        "id": "4dad7c6dd018ed69"
      },
      "id": "4dad7c6dd018ed69"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Percentage Correctly Classified')\n",
        "plt.title('Training Accuracy')\n",
        "plt.plot(model_mse.accuracy_train_data_during_training, 'r-.', label='Logistic (MSE)')\n",
        "plt.plot(model_ce.accuracy_train_data_during_training, 'g-', label='Logistic (Cross-Entropy)')\n",
        "plt.legend(loc='best')"
      ],
      "metadata": {
        "id": "c6628eff34ccffd8"
      },
      "id": "c6628eff34ccffd8",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Percentage Correctly Classified')\n",
        "plt.title('Test Accuracy')\n",
        "plt.plot(model_mse.accuracy_test_data_during_training, 'r-.', label='Logistic (MSE)')\n",
        "plt.plot(model_ce.accuracy_test_data_during_training, 'g-', label='Logistic (Cross-Entropy)')\n",
        "plt.legend(loc='best')"
      ],
      "metadata": {
        "id": "76a96c9a27288281"
      },
      "id": "76a96c9a27288281",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain the differences between MSE and Cross Entropy Loss in logistic regression, why is one of the versions of Logistic Regression learning faster in terms of gradient descent iterations than the other? (5 points)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "738665c431fef363"
      },
      "id": "738665c431fef363"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "70d405eb639852ad"
      },
      "id": "70d405eb639852ad"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the plots demonstrating the effects of the learning rate and the number of iterations parameters on the training process (hyperparameter tuning) (5 points)"
      ],
      "metadata": {
        "id": "Z--FQaeJF-v1"
      },
      "id": "Z--FQaeJF-v1"
    },
    {
      "cell_type": "code",
      "source": [
        "### fill here ###"
      ],
      "metadata": {
        "id": "zKJaVVsgF_R8"
      },
      "id": "zKJaVVsgF_R8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decision Tree (35 points)\n",
        "\n",
        "Implement Decision Tree Method (5 points)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "851b964febdb3d01"
      },
      "id": "851b964febdb3d01"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "class DecisionTree:\n",
        "    def __init__(self, columns, depth=None):\n",
        "        self.max_depth = depth\n",
        "        self.columns = columns\n",
        "\n",
        "    def fit(self, train_data, train_label):\n",
        "        # implement here\n",
        "        pass\n",
        "\n",
        "    def predict(self, test_data):\n",
        "        # implement here\n",
        "        pass\n",
        "\n",
        "    def print_tree(self):\n",
        "        # Implement your print function for your decision tree using preorder traversal\n",
        "        # Internal nodes should be printed as feature_name <= threshold value\n",
        "        # Leaf nodes should be printed as Left/Right Leaf: label value\n",
        "        # Add an extra tab (\\t) for each depth level to better visualize the tree structure\n",
        "        pass"
      ],
      "metadata": {
        "id": "66b41a4389791aa3"
      },
      "id": "66b41a4389791aa3",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate your implementation using libraries (5 points)\n",
        "\n",
        "(you can generate synthetic data using numpy of import another toy dataset from sklearn)\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5d5595ab12e2a999"
      },
      "id": "5d5595ab12e2a999"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "### fill here ###"
      ],
      "metadata": {
        "id": "2bf4874bfbe28d11"
      },
      "id": "2bf4874bfbe28d11",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment\n",
        "\n",
        "Dataset preparation"
      ],
      "metadata": {
        "collapsed": false,
        "id": "c18333b2fcaae3bc"
      },
      "id": "c18333b2fcaae3bc"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "data = pd.read_csv(url)\n",
        "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "X = data[['Pclass', 'Sex', 'SibSp','Parch','Fare']].values\n",
        "Y = data['Survived'].values\n",
        "columns = data.columns\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "500c508d6ec62491"
      },
      "id": "500c508d6ec62491",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Decision Tree Method on the dataset directly (10 points)\n",
        "Show accuracy score on test data"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ce26839f952015f1"
      },
      "id": "ce26839f952015f1"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "### fill here ###"
      ],
      "metadata": {
        "id": "d2a6f5da032e5fe7"
      },
      "id": "d2a6f5da032e5fe7",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the decision tree (5 points)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "d34f1ce022b357a1"
      },
      "id": "d34f1ce022b357a1"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "model_dt.print_tree()"
      ],
      "metadata": {
        "id": "304bd6ae4271856c"
      },
      "id": "304bd6ae4271856c",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the impact of the max_depth hyperparameter on the accuracy score (hyperparameter tuning) (5 points)"
      ],
      "metadata": {
        "id": "oqa92V5xFldO"
      },
      "id": "oqa92V5xFldO"
    },
    {
      "cell_type": "code",
      "source": [
        "### fill here ###"
      ],
      "metadata": {
        "id": "INCKVB_aFrnm"
      },
      "id": "INCKVB_aFrnm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "X = iris['data']\n",
        "Y = iris['target']\n",
        "columns = iris['feature_names']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "4c40abe4d9790def"
      },
      "id": "4c40abe4d9790def",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show your implementation on different dataset (5 points)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5bb309fe38aa37cf"
      },
      "id": "5bb309fe38aa37cf"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "### fill here ###"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-12-04T22:15:26.949679Z",
          "start_time": "2024-12-04T22:15:26.939369Z"
        },
        "id": "9790eb012ba39334"
      },
      "id": "9790eb012ba39334",
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}